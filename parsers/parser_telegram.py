"""–ü–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç:
- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram API —á–µ—Ä–µ–∑ Telethon
- –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ ClickHouse
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import asyncio
import re
import os
import sys
from datetime import datetime
from clickhouse_driver import Client as ClickHouseClient
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞—Ä—Å–µ—Ä–∞–º –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.join(os.path.dirname(__file__)))
from gen_api_classifier import GenApiNewsClassifier
from telethon import TelegramClient, events
from telethon.tl.functions.messages import GetHistoryRequest

# Load environment variables from .env file
load_dotenv()

# Telegram API credentials
# You need to get these from https://my.telegram.org/
API_ID = Config.TELEGRAM_API_ID
API_HASH = Config.TELEGRAM_API_HASH
PHONE = Config.TELEGRAM_PHONE  # Your phone number with country code

# List of Telegram channels to parse (use channel usernames without @)
TELEGRAM_CHANNELS = [
    'infantmilitario',
    'genshtab24',
    'new_militarycolumnist',
    'inosmichannel',
    'operline_ru',
    'rian_ru',           # –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏
    'bbcrussian',        # BBC Russian
    'meduzalive',        # –ú–µ–¥—É–∑–∞
    'breakingmash',      # Mash
    'readovkanews'       # Readovka
    # Add more channels as needed
]

def create_ukraine_tables_if_not_exists():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ ClickHouse –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è Telegram –Ω–æ–≤–æ—Å—Ç–µ–π.
    
    –°–æ–∑–¥–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö 'news' –∏ —Ç–∞–±–ª–∏—Ü—É 'telegram_headlines'
    —Å –ø–æ–ª—è–º–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∫–∞–Ω–∞–ª–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.
    """
    client = ClickHouseClient(
        host=Config.CLICKHOUSE_HOST,
        port=Config.CLICKHOUSE_NATIVE_PORT,
        user=Config.CLICKHOUSE_USER,
        password=Config.CLICKHOUSE_PASSWORD
    )
    
    # Create database if not exists
    client.execute('CREATE DATABASE IF NOT EXISTS news')
    
    # Create table if not exists
    client.execute('''
    CREATE TABLE IF NOT EXISTS news.telegram_headlines (
        id UUID DEFAULT generateUUIDv4(),
        title String,
        content String,
        channel String,
        message_id Int64,
        message_link String,
        source String DEFAULT 'telegram',
        category String DEFAULT 'other',
        published_date DateTime DEFAULT now()
    ) ENGINE = MergeTree()
    ORDER BY (published_date, id)
    ''')

async def get_telegram_messages(client, channel, limit=100):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–∞.
    
    Args:
        client: Telegram –∫–ª–∏–µ–Ω—Ç
        channel (str): –ò–º—è –∫–∞–Ω–∞–ª–∞ –±–µ–∑ @
        limit (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
    
    Returns:
        tuple: (messages, entity) - –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ entity –∫–∞–Ω–∞–ª–∞
    """
    try:
        entity = await client.get_entity(channel)
        
        # Get messages
        history = await client(GetHistoryRequest(
            peer=entity,
            offset_id=0,
            offset_date=None,
            add_offset=0,
            limit=limit,
            max_id=0,
            min_id=0,
            hash=0
        ))
        
        return history.messages, entity
    
    except Exception as e:
        print(f"Error getting messages from {channel}: {e}")
        return [], None

def clean_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç —Ä–µ–∫–ª–∞–º—ã, –ø—Ä–∏–∑—ã–≤–æ–≤ –∫ –ø–æ–¥–ø–∏—Å–∫–µ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    if not text:
        return ""
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
    try:
        text = str(text)
    except UnicodeDecodeError:
        text = text.encode('utf-8', errors='replace').decode('utf-8')
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è—â–∏–µ —Ç–æ–ª—å–∫–æ –∏–∑ —ç–º–æ–¥–∑–∏
    emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF\U0001F018-\U0001F0F5\U0001F200-\U0001F2FF]+'
    emoji_only = re.sub(r'[^\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF\U0001F018-\U0001F0F5\U0001F200-\U0001F2FF\s]', '', text).strip()
    
    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ —ç–º–æ–¥–∑–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤ - —ç—Ç–æ —Å–ø–∞–º
    if emoji_only and len(emoji_only) > 0 and len(text.strip()) < 50:
        return ""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏ (>30% –æ—Ç —Ç–µ–∫—Å—Ç–∞)
    emoji_count = len(re.findall(emoji_pattern, text))
    text_length = len(re.sub(emoji_pattern, '', text).strip())
    if emoji_count > 0 and text_length > 0 and (emoji_count / (emoji_count + text_length)) > 0.3:
        return ""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ —Å–º—ã—Å–ª–∞
    if len(text.strip()) < 20:
        return ""
    
    # –£–¥–∞–ª—è–µ–º URL-–∞–¥—Ä–µ—Å–∞
    text = re.sub(r'https?://\S+', '', text)
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–∏–∑—ã–≤—ã –∫ –ø–æ–¥–ø–∏—Å–∫–µ (—Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
    spam_patterns = [
        r'[‚ùóÔ∏è‚ö°üî•üí•]*\s*[–ü–ø]–æ–¥–ø–∏—Å[—ã—å]–≤–∞–π—Å—è?\s+–Ω–∞\s+\S+',  # –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ Mash
        r'[–ü–ø]–æ–¥–ø–∏—à[–∏–µ—É]—Ç–µ—Å?—å?\s+–Ω–∞\s+\S+',  # –ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ –∫–∞–Ω–∞–ª
        r'[–ü–ø]–æ–¥–ø–∏—à[–∏–µ—É]—Ç–µ—Å?—å?\s+‚û°Ô∏è?\s*\S+',  # –ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å ‚û°Ô∏è
        r'[–ß—á]–∏—Ç–∞–π(?:—Ç–µ)?\s+(?:–Ω–∞—Å|–Ω–∞—à\s+–∫–∞–Ω–∞–ª)',  # –ß–∏—Ç–∞–π—Ç–µ –Ω–∞—Å
        r'[–°—Å]–ª–µ–¥–∏—Ç–µ?\s+–∑–∞\s+(?:–Ω–∞–º–∏|–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏)',  # –°–ª–µ–¥–∏—Ç–µ –∑–∞ –Ω–∞–º–∏
        r'[–í–≤]—Å—Ç—É–ø–∞–π(?:—Ç–µ)?\s+–≤\s+(?:–Ω–∞—à)?\s*(?:–∫–∞–Ω–∞–ª|–≥—Ä—É–ø–ø—É)',  # –í—Å—Ç—É–ø–∞–π—Ç–µ –≤ –∫–∞–Ω–∞–ª
        r'[–ñ–∂]–º–∏\s+‚û°Ô∏è?\s*\S+',  # –ñ–º–∏ ‚û°Ô∏è
        r'‚û°Ô∏è\s*[–ü–ø]–æ–¥–ø–∏—Å',  # ‚û°Ô∏è –ü–æ–¥–ø–∏—Å
        r'@\w+\s*[-‚Äì‚Äî]\s*–ø–æ–¥–ø–∏—Å',  # @channel - –ø–æ–¥–ø–∏—Å
        r'[–ò–∏]—Å—Ç–æ—á–Ω–∏–∫:\s*@?\w+',  # –ò—Å—Ç–æ—á–Ω–∏–∫: @channel
        r'\|\s*[–ü–ø]–æ–¥–ø–∏—Å',  # | –ü–æ–¥–ø–∏—Å
        r'üîî\s*[–ü–ø]–æ–¥–ø–∏—Å',  # üîî –ü–æ–¥–ø–∏—Å
        r'[–ü–ø]–æ–¥–ø–∏—Å[—ã—å]–≤–∞–π—Å—è?\s*[‚ùóÔ∏è‚ö°üî•üí•]*',  # –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è!
        r'[–ü–ø]–æ–¥–ø–∏—à[–∏–µ—É]—Ç–µ—Å?—å?\s*[‚ùóÔ∏è‚ö°üî•üí•]*',  # –ü–æ–¥–ø–∏—à–∏—Ç–µ—Å—å!
        r'[–°—Å]–ª–µ–¥–∏—Ç–µ?\s+–∑–∞\s+–Ω–∞–º–∏\s*[‚ùóÔ∏è‚ö°üî•üí•]*',  # –°–ª–µ–¥–∏—Ç–µ –∑–∞ –Ω–∞–º–∏!
    ]
    
    for pattern in spam_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫ (—Ç–∏–ø–∞ ‚ùó, ‚ö°, üî• –∏ —Ç.–¥.)
    text = re.sub(r'^[‚ùóÔ∏è‚ö°üî•üí•üö®‚≠êÔ∏è‚úÖ‚ùå‚õîÔ∏èüî¥üü¢üîµ‚ö™Ô∏èüü°üü£üü§‚¨õÔ∏è‚¨úÔ∏è‚ñ™Ô∏è‚ñ´Ô∏è]+\s*', '', text)
    text = re.sub(r'\s*[‚ùóÔ∏è‚ö°üî•üí•üö®‚≠êÔ∏è‚úÖ‚ùå‚õîÔ∏èüî¥üü¢üîµ‚ö™Ô∏èüü°üü£üü§‚¨õÔ∏è‚¨úÔ∏è‚ñ™Ô∏è‚ñ´Ô∏è]+$', '', text)
    
    # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —ç–º–æ–¥–∑–∏ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞ (–±–æ–ª–µ–µ 2 –ø–æ–¥—Ä—è–¥)
    text = re.sub(r'([‚ùóÔ∏è‚ö°üî•üí•üö®‚≠êÔ∏è‚úÖ‚ùå‚õîÔ∏è])\1{2,}', r'\1', text)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–æ—è—Ç —Ç–æ–ª—å–∫–æ –∏–∑ —Å–∏–º–≤–æ–ª–æ–≤ –∏ —ç–º–æ–¥–∑–∏
    lines = text.split('\n')
    clean_lines = []
    for line in lines:
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏ —Ç–æ–ª—å–∫–æ –∏–∑ —Å–∏–º–≤–æ–ª–æ–≤
        stripped = re.sub(r'[‚ùóÔ∏è‚ö°üî•üí•üö®‚≠êÔ∏è‚úÖ‚ùå‚õîÔ∏èüî¥üü¢üîµ‚ö™Ô∏èüü°üü£üü§‚¨õÔ∏è‚¨úÔ∏è‚ñ™Ô∏è‚ñ´Ô∏è‚û°Ô∏èüîî|‚Äî‚Äì-]+', '', line).strip()
        if stripped and len(stripped) > 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏
            clean_lines.append(line)
    
    text = '\n'.join(clean_lines)
    
    # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'\s+', ' ', text).strip()
    
    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –æ–¥–∏–Ω–æ—á–Ω—ã–µ —ç–º–æ–¥–∑–∏ –ø—Ä–∏–∑—ã–≤–æ–≤
    text = re.sub(r'^\s*[‚ùóÔ∏è‚ö°üî•‚û°Ô∏èüîî]\s*', '', text)
    text = re.sub(r'\s*[‚ùóÔ∏è‚ö°üî•‚û°Ô∏èüîî]\s*$', '', text)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω—å—à–µ 20 —Å–∏–º–≤–æ–ª–æ–≤, —ç—Ç–æ —Å–ø–∞–º
    if len(text.strip()) < 20:
        return ""
    
    return text

def determine_category(title, content, channel):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
    
    Args:
        title (str): –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏
        content (str): –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
        channel (str): –ò–º—è –∫–∞–Ω–∞–ª–∞
    
    Returns:
        str: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–ª–∏ None –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ 'other'
    """
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        from parsers.improved_classifier import classifier
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç (–ø–µ—Ä–µ–¥–∞–µ–º title –∏ content –æ—Ç–¥–µ–ª—å–Ω–æ)
        category = classifier.classify(title, content)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "other"
        if category == 'other':
            return None
            
        return category
        
    except Exception as e:
        print(f"Error classifying message: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ª–æ–≥–∏–∫—É –ø–æ –∫–∞–Ω–∞–ª–∞–º
        military_channels = ['infantmilitario', 'genshtab24', 'new_militarycolumnist', 'operline_ru']
        
        if channel in military_channels:
            return 'military_operations'
        else:
            return 'information_social'

async def parse_telegram_channels(limit=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ Telegram –∫–∞–Ω–∞–ª–æ–≤.
    
    –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Telegram API, –ø–æ–ª—É—á–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–æ–≤,
    –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ ClickHouse.
    """
    # Create table if not exists
    create_ukraine_tables_if_not_exists()
    
    # Initialize Telegram client with session file
    session_file = os.path.join(os.path.dirname(__file__), 'telegram_session')
    client = TelegramClient(session_file, API_ID, API_HASH)
    
    try:
        print("Connecting to Telegram...")
        await client.start(phone=PHONE)
        print("Successfully connected to Telegram")
        
        # Check if we're authorized
        if not await client.is_user_authorized():
            print("User not authorized. Please run this script interactively first to authorize.")
            return
        
        # Initialize ClickHouse client
        clickhouse_client = ClickHouseClient(
            host=Config.CLICKHOUSE_HOST,
            port=Config.CLICKHOUSE_NATIVE_PORT,
            user=Config.CLICKHOUSE_USER,
            password=Config.CLICKHOUSE_PASSWORD
        )
        
        # Get existing message IDs to avoid duplicates
        existing_messages = {}
        for channel in TELEGRAM_CHANNELS:
            try:
                result = clickhouse_client.execute(
                    f"SELECT message_id FROM news.telegram_headlines WHERE channel = '{channel}'"
                )
                existing_messages[channel] = {row[0] for row in result}
            except Exception as e:
                print(f"Warning: Could not get existing messages for {channel}: {e}")
                existing_messages[channel] = set()
        
        # Parse each channel
        for channel in TELEGRAM_CHANNELS:
            try:
                print(f"\nParsing channel: {channel}")
                
                # Get messages from channel
                messages_limit = limit if limit else 100
                messages, entity = await get_telegram_messages(client, channel, limit=messages_limit)
                
                if not messages or not entity:
                    print(f"Could not get messages from {channel}")
                    continue
                
                headlines_data = []
                skipped_count = 0
                skipped_other_count = 0
                
                for message in messages:
                    # Skip empty messages
                    if not message.message:
                        continue
                    
                    # Check if this message already exists in the database
                    if message.id in existing_messages.get(channel, set()):
                        skipped_count += 1
                        continue
                    
                    # Extract title (first line) and content
                    message_text = message.message
                    title_match = re.match(r'^(.+?)(?:\n|$)', message_text)
                    title = clean_text(title_match.group(1)) if title_match else "No title"
                    content = clean_text(message_text)
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                    if not content or len(content.strip()) < 20:
                        print(f"Skipped spam/empty message: {message_text[:50]}...")
                        continue
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ Gen-API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
                    try:
                        classifier = GenApiNewsClassifier()
                        ai_result = classifier.classify(title, content)
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Gen-API –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                        category = ai_result['category_name']
                        social_tension_index = ai_result['social_tension_index']
                        spike_index = ai_result['spike_index']
                        ai_confidence = ai_result['confidence']
                        ai_category = ai_result['category_name']
                        
                        print(f"Gen-API –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {category} (–Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç—å: {social_tension_index}, –≤—Å–ø–ª–µ—Å–∫: {spike_index})")
                        
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ Gen-API –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
                        # Fallback –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º improved_classifier
                        category_result = determine_category(title, content, channel)
                        if isinstance(category_result, tuple):
                            category = category_result[0]  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        else:
                            category = category_result
                        social_tension_index = 0.0
                        spike_index = 0.0
                        ai_confidence = 0.0
                        ai_category = category

                    # Skip if category is None (other category)
                    if category is None:
                        skipped_other_count += 1
                        continue
                    
                    # Create message link
                    message_link = f"https://t.me/{entity.username}/{message.id}" if hasattr(entity, 'username') else ""
                    
                    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–≤–æ–¥ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    try:
                        safe_title = title[:50] + ('...' if len(title) > 50 else '')
                        print(f"Title: {safe_title}")
                        print(f"Category: {category}")
                    except UnicodeEncodeError:
                        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π, –∑–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                        safe_title = title.encode('utf-8', errors='replace').decode('utf-8')[:50]
                        print(f"Title: {safe_title}{'...' if len(title) > 50 else ''}")
                        print(f"Category: {category}")
                    print(f"Message ID: {message.id}")
                    print("-" * 40)
                    
                    # Add to data for insertion
                    headlines_data.append({
                        'title': title,
                        'content': content,
                        'channel': channel,
                        'message_id': message.id,
                        'message_link': message_link,
                        'category': category,
                        'source': 'telegram',
                        'social_tension_index': social_tension_index,
                        'spike_index': spike_index,
                        'ai_category': ai_category,
                        'ai_confidence': ai_confidence,
                        'ai_classification_metadata': 'gen_api_classification',
                        'published_date': datetime.now()
                    })
                
                # Insert data into ClickHouse if we have any
                if headlines_data:
                    clickhouse_client.execute(
                        'INSERT INTO news.telegram_headlines (title, content, channel, message_id, message_link, category, source, social_tension_index, spike_index, ai_category, ai_confidence, ai_classification_metadata, published_date) VALUES',
                        headlines_data
                    )
                    print(f"Added {len(headlines_data)} records to database from channel {channel}")
                
                if skipped_count > 0:
                    print(f"Skipped {skipped_count} duplicates from channel {channel}")
                
                if skipped_other_count > 0:
                    print(f"Skipped {skipped_other_count} 'other' category messages from channel {channel}")
                
            except Exception as e:
                print(f"Error processing channel {channel}: {e}")
            
            # Sleep to avoid rate limiting
            await asyncio.sleep(2)
    
    finally:
        await client.disconnect()

def main(limit=None):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞"""
    try:
        print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ Telegram")
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–æ–≤
        asyncio.run(parse_telegram_channels(limit=limit))
        
        print("–ü–∞—Ä—Å–µ—Ä Telegram –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")
        sys.exit(0)
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–∞—Ä—Å–µ—Ä–µ Telegram: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # Create .env file if it doesn't exist
    if not os.path.exists('.env'):
        with open('.env', 'w') as f:
            f.write("TELEGRAM_API_ID=\nTELEGRAM_API_HASH=\nTELEGRAM_PHONE=\n")
        print("Created .env file. Please fill in your Telegram API credentials.")
        print("You can get API_ID and API_HASH from https://my.telegram.org/")
        exit(1)
    
    # Check if credentials are set
    if not API_ID or not API_HASH or not PHONE:
        print("Please set your Telegram API credentials in the .env file")
        exit(1)
    
    # Run the parser
    import argparse
    parser = argparse.ArgumentParser(description='Parser for Telegram channels')
    parser.add_argument('--limit', type=int, default=None, help='Limit messages to parse (for testing)')
    args = parser.parse_args()
    
    main(limit=args.limit)
